### Hi there ðŸ‘‹

My name is [Jiancheng (JC) Liu](https://ljcc0930.github.io/). I am a graduate student in Computer Science and Engineering at Michigan State University. I currently work at [OPTML Group](https://www.optml-group.com/), advised by [Prof. Sijia Liu](https://lsjxjtu.github.io/). My research goal is to foster a seamless integration of AI with humanity, through a deeper comprehension of natural laws and societal dynamics. A recent topic of my research is enhancing AI's trustworthiness through *Machine Unlearning*.

I received my B.E. in computer science from the [Institute for Interdisciplinary Information Sciences](https://iiis.tsinghua.edu.cn/en/) ([Yao Class](https://iiis.tsinghua.edu.cn/en/yaoclass/), headed by [Prof. Andrew Chi-Chih Yao](https://iiis.tsinghua.edu.cn/yao/)), Tsinghua University. I am fortunate to have been advised by [Prof. Shi-Min Hu](https://cg.cs.tsinghua.edu.cn/shimin.htm) on my undergraduate research and bachelor thesis. In 2018, I had some wonderful times working with [Prof. Wojciech Matusik](https://cdfg.mit.edu/wojciech) and [Dr. Yuanming Hu](https://yuanming.taichi.graphics/) at MIT.

Before studying at MSU, I joined [Taichi Graphics Technology, Inc.](https://taichi.graphics/) as a start-up member in 2021. During my employment, I focused on developing [Taichi Lang](https://github.com/taichi-dev/taichi) and delving into differentiable physics.

</br>

**Email:** liujia45 (at) msu (dot) edu [[CV](https://ljcc0930.github.io/docs/cv_jiancheng.pdf)] [[Google Scholar](https://scholar.google.com/citations?user=ReWNzl4AAAAJ)] [[GitHub](https://github.com/ljcc0930)]

### My publications by category
|Paper Title|Venue|<div style="width:350px">Repository</div>|
|---|:---:|:---:|
|**Unlearning for LLMs**||
|[Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning](https://arxiv.org/abs/2410.07163)| In Submission | [![OPTML-Group/Unlearn-Simple](https://img.shields.io/badge/Unlearn--Simple-grey?logo=github)](https://github.com/OPTML-Group/Unlearn-Simple) |
|[WAGLE: Strategic Weight Attribution for Effective and Modular Unlearning in Large Language Models](https://arxiv.org/abs/2410.17509)| NeurIPS'24 | [![OPTML-Group/WAGLE](https://img.shields.io/badge/WAGLE-grey?logo=github)](https://github.com/OPTML-Group/WAGLE) |
|[SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning](https://arxiv.org/abs/2404.18239)| EMNLP'24 |[![OPTML-Group/Unlearn-WorstCase](https://img.shields.io/badge/SOUL-grey?logo=github)](https://github.com/OPTML-Group/SOUL)|
|||
|**Unlearning for Diffusion Models**||
|[Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models](https://arxiv.org/abs/2405.15234)| NeurIPS'24 |[![OPTML-Group/AdvUnlearn](https://img.shields.io/badge/AdvUnlearn-grey?logo=github)](https://github.com/OPTML-Group/AdvUnlearn)|
|[UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2402.11846)| NeurIPS'24 D&B |[![OPTML-Group/UnlearnCanvas](https://img.shields.io/badge/UnlearnCanvas-grey?logo=github)](https://github.com/OPTML-Group/UnlearnCanvas)|
|[To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images... For Now](https://arxiv.org/abs/2310.11868)| ECCV'24 |[![OPTML-Group/Diffusion-MU-Attack](https://img.shields.io/badge/Diffusion--MU--Attack-grey?logo=github)](https://github.com/OPTML-Group/Diffusion-MU-Attack)|
|[SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation](https://arxiv.org/abs/2310.12508)|ICLR'24 (**Spotlight**)|[![OPTML-Group/Unlearn-Saliency](https://img.shields.io/badge/Unlearn--Saliency-grey?logo=github)](https://github.com/OPTML-Group/Unlearn-Saliency)|
|||
|**Unlearning for Classification Models**||
|[Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification](https://arxiv.org/abs/2412.16780)| In Submission |[![OPTML-Group/Changchangsun/Forget-Vector](https://img.shields.io/badge/Forget--Vector-grey?logo=github)](https://github.com/Changchangsun/Forget-Vector)|
|[Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning](https://arxiv.org/abs/2403.07362)| ECCV'24 |[![OPTML-Group/Unlearn-WorstCase](https://img.shields.io/badge/Unlearn--WorstCase-grey?logo=github)](https://github.com/OPTML-Group/Unlearn-WorstCase)|
|[Model Sparsity Can Simplify Machine Unlearning](https://arxiv.org/abs/2304.04934)|NeurIPS'23 (**Spotlight**)|[![OPTML-Group/Unlearn-Sparse](https://img.shields.io/badge/Unlearn--Sparse-grey?logo=github)](https://github.com/OPTML-Group/Unlearn-Sparse)|
|||
|**Physical-informed ML**||
|[Towards Universal Mesh Movement Networks](https://arxiv.org/abs/2407.00382)| NeurIPS'24 (**Spotlight**) | [![mesh-adaptation/UM2N](https://img.shields.io/badge/UM2N-grey?logo=github)](https://github.com/mesh-adaptation/UM2N) |
|[Complex Locomotion Skill Learning via Differentiable Physics](https://arxiv.org/abs/2206.02341)| Technical Report | [![erizmr/Complex-locomotion-skill-learning-via-differentiable-physics](https://img.shields.io/badge/Complex--learning-grey?logo=github)](https://github.com/erizmr/Complex-locomotion-skill-learning-via-differentiable-physics) |
|[ChainQueen: A Real-Time Differentiable Physical Simulator for Soft Robotics](https://arxiv.org/abs/1810.01054)| ICRA'19 |[![yuanming-hu/ChainQueen](https://img.shields.io/badge/ChainQueen-grey?logo=github)](https://github.com/yuanming-hu/ChainQueen)|
